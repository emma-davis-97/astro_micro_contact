{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/camp/home/davise/home/users/davise/conda/envs/lazemap_env/lib/python3.8/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 8.1.2. Several security issues (CVE-2021-27921, CVE-2021-25290, CVE-2021-25291, CVE-2021-25293, and more) have been fixed in pillow 8.1.2 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "# IMPORT PACKAGES\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import filters, measure, morphology, io\n",
    "from skimage.segmentation import clear_border\n",
    "from aicsimageio import AICSImage\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# TO SUPPRESS WARNINGS BEING PRINTED\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET PARAMETERS FOR ANALYSIS\n",
    "c1gaussRad = 2.0\n",
    "c2gaussRad = 2.0\n",
    "c1thresholdMethod = \"isodata\"\n",
    "c2thresholdMethod = \"isodata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 files found\n"
     ]
    }
   ],
   "source": [
    "# DIRECTORY SET UP\n",
    "main_dir = \"/camp/home/davise/home/shared/thackrm/Batch_processing_images/\"\n",
    "image_dir = os.path.join(main_dir, \"Images\")\n",
    "results_dir = os.path.join(main_dir, \"results\")\n",
    "sense_check_dir = os.path.join(main_dir, \"sense_check\")\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "if not os.path.exists(sense_check_dir):\n",
    "    os.makedirs(sense_check_dir)\n",
    "\n",
    "fileList = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))\n",
    "            and f.endswith('.czi')]\n",
    "print(f\"{len(fileList)} files found\")\n",
    "\n",
    "# LIST FOR ALL RESULTS TABLE\n",
    "all_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(filePath):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    extractedName = extract_file_name(filePath)\n",
    "    print(f\"Processing: {extractedName}\")\n",
    "\n",
    "    # CREATE SENSE CHECK DIRECTORY FOR CURRENT IMG\n",
    "    image_sense_check_dir = os.path.join(sense_check_dir, extractedName)\n",
    "    if not os.path.exists(image_sense_check_dir):\n",
    "        os.makedirs(image_sense_check_dir)\n",
    "    \n",
    "    img = AICSImage(filePath)\n",
    "    data = img.get_image_data(\"CZYX\", S=0, T=0)\n",
    "    \n",
    "    # GET INFO TO CONVERT FROM PIXELS TO VOXELS\n",
    "    voxel_size = img.physical_pixel_sizes  # Get voxel dimensions (z, y, x) in microns\n",
    "    voxel_volume = voxel_size.Z * voxel_size.Y * voxel_size.X  # Calculate voxel volume in cubic microns\n",
    "    \n",
    "    # SPLIT CHANNELS\n",
    "    c1 = data[0, :, :, :]\n",
    "    c2 = data[1, :, :, :]\n",
    "\n",
    "    # SAVE ORIG IMAGES AS SENSE CHECK\n",
    "    for z in range(0, c1.shape[0], 50):  # Save every 50th slice\n",
    "        io.imsave(os.path.join(image_sense_check_dir, f\"c1_orig_z{z}.png\"), c1[z, :, :])\n",
    "        io.imsave(os.path.join(image_sense_check_dir, f\"c2_orig_z{z}.png\"), c2[z, :, :])\n",
    "    \n",
    "    # GAUSSIAN BLUR USING OPENCV\n",
    "    c1_blurred = np.array([cv2.GaussianBlur(c1[z, :, :], (0, 0), c1gaussRad) for z in range(c1.shape[0])])\n",
    "    c2_blurred = np.array([cv2.GaussianBlur(c2[z, :, :], (0, 0), c2gaussRad) for z in range(c2.shape[0])])\n",
    "    \n",
    "    # SAVE BLUR IMAGES AS SENSE CHECK\n",
    "    for z in range(0, c1_blurred.shape[0], 50):\n",
    "        io.imsave(os.path.join(image_sense_check_dir, f\"c1_blurred_z{z}.png\"), c1_blurred[z, :, :])\n",
    "        io.imsave(os.path.join(image_sense_check_dir, f\"c2_blurred_z{z}.png\"), c2_blurred[z, :, :])\n",
    "    \n",
    "    # THRESHOLD\n",
    "    c1_binary = np.array([c1_blurred[z, :, :] > filters.threshold_isodata(c1_blurred[z, :, :]) for z in range(c1_blurred.shape[0])])\n",
    "    c2_binary = np.array([c2_blurred[z, :, :] > filters.threshold_isodata(c2_blurred[z, :, :]) for z in range(c2_blurred.shape[0])])\n",
    "        \n",
    "    # SAVE BINARY IMAGES AS SENSE CHECK\n",
    "    for z in range(0, c1_binary.shape[0], 50):\n",
    "        io.imsave(os.path.join(image_sense_check_dir, f\"c1_binary_z{z}.png\"), c1_binary[z, :, :].astype(np.uint8) * 255)\n",
    "        io.imsave(os.path.join(image_sense_check_dir, f\"c2_binary_z{z}.png\"), c2_binary[z, :, :].astype(np.uint8) * 255)\n",
    "    \n",
    "    # CALC. OVERLAP\n",
    "    overlap = np.logical_and(c1_binary, c2_binary)\n",
    "    \n",
    "    # SAVE OVERLAP AS SENSE CHECK\n",
    "    for z in range(0, overlap.shape[0], 50):\n",
    "        io.imsave(os.path.join(image_sense_check_dir, f\"overlap_z{z}.png\"), overlap[z, :, :].astype(np.uint8) * 255)\n",
    "    \n",
    "    # LABEL OBJECTS AND CALC. VOLUME\n",
    "    c1_labels = measure.label(c1_binary, connectivity=1)\n",
    "    c2_labels = measure.label(c2_binary, connectivity=1)\n",
    "    overlap_labels = measure.label(overlap, connectivity=1)\n",
    "    \n",
    "    # SAVE LABEL IMAGES AS SENSE CHECK\n",
    "    for z in range(0, c1_labels.shape[0], 50):\n",
    "        io.imsave(os.path.join(image_sense_check_dir, f\"c1_labels_z{z}.png\"), c1_labels[z, :, :].astype(np.uint16))\n",
    "        io.imsave(os.path.join(image_sense_check_dir, f\"c2_labels_z{z}.png\"), c2_labels[z, :, :].astype(np.uint16))\n",
    "        io.imsave(os.path.join(image_sense_check_dir, f\"overlap_labels_z{z}.png\"), overlap_labels[z, :, :].astype(np.uint16))\n",
    "    \n",
    "    c1_props = measure.regionprops(c1_labels)\n",
    "    c2_props = measure.regionprops(c2_labels)\n",
    "    overlap_props = measure.regionprops(overlap_labels)\n",
    "    \n",
    "    c1_volume = sum([prop.area for prop in c1_props]) * voxel_volume\n",
    "    c2_volume = sum([prop.area for prop in c2_props]) * voxel_volume\n",
    "    overlap_volume = sum([prop.area for prop in overlap_props]) * voxel_volume\n",
    "    \n",
    "    print(f\"Channel 1 volume: {c1_volume}\")\n",
    "    print(f\"Channel 2 volume: {c2_volume}\")\n",
    "    print(f\"Overlap volume: {overlap_volume}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Compile results into a list\n",
    "    all_results.append({\n",
    "        \"Image\": extractedName,\n",
    "        \"Channel\": \"Channel 1\",\n",
    "        \"Volume (microns^3)\": c1_volume,\n",
    "        \"% Overlap\": 100.0 * (overlap_volume / c1_volume) if c1_volume != 0 else np.nan\n",
    "    })\n",
    "    all_results.append({\n",
    "        \"Image\": extractedName,\n",
    "        \"Channel\": \"Channel 2\",\n",
    "        \"Volume (microns^3)\": c2_volume,\n",
    "        \"% Overlap\": 100.0 * (overlap_volume / c2_volume) if c2_volume != 0 else np.nan\n",
    "    })\n",
    "    all_results.append({\n",
    "        \"Image\": extractedName,\n",
    "        \"Channel\": \"Overlap\",\n",
    "        \"Volume (microns^3)\": overlap_volume,\n",
    "        \"% Overlap\": np.nan\n",
    "    })\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    return elapsed_time\n",
    "\n",
    "def extract_file_name(filePath):\n",
    "    fileName = os.path.basename(filePath)\n",
    "    fileNameWithoutExt = os.path.splitext(fileName)[0]\n",
    "    return fileNameWithoutExt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: BDAU7_2c-04-Airyscan_Processing-02\n",
      "Channel 1 volume: 37672.607163102155\n",
      "Channel 2 volume: 4452.128245535758\n",
      "Overlap volume: 1028.035091008305\n",
      "\n",
      "\n",
      "Processed 1/3 images. ETA all images finished: 16:00\n",
      "Processing: BDAU7_2c-08-Airyscan_Processing-03\n",
      "Channel 1 volume: 30772.44441698522\n",
      "Channel 2 volume: 4682.689762959804\n",
      "Overlap volume: 621.4379247180667\n",
      "\n",
      "\n",
      "Processed 2/3 images. ETA all images finished: 16:00\n",
      "Processing: BDAU7_2c-01-Airyscan_Processing-01\n"
     ]
    }
   ],
   "source": [
    "total_images = len(fileList)\n",
    "total_time = 0\n",
    "\n",
    "# APPLY TO EACH IMAGE IN LIST\n",
    "for idx, file in enumerate(fileList):\n",
    "    elapsed_time = process_image(os.path.join(image_dir, file))\n",
    "    total_time += elapsed_time\n",
    "    \n",
    "    # CALC. AND PRINT ETA\n",
    "    remaining_images = total_images - (idx + 1)\n",
    "    avg_time_per_image = total_time / (idx + 1)\n",
    "    eta_seconds = remaining_images * avg_time_per_image\n",
    "    eta = datetime.now() + timedelta(seconds=eta_seconds)\n",
    "    print(f\"Processed {idx + 1}/{total_images} images. ETA all images finished: {eta.strftime('%H:%M')}\")\n",
    "\n",
    "# STORE ALL RESULTS IN ONE CSV\n",
    "all_results_df = pd.DataFrame(all_results)\n",
    "all_results_df.to_csv(os.path.join(results_dir, \"compiled_results.csv\"), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Local lazemap_env",
   "language": "python3",
   "name": "rik_local_lazemap_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
